{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Introduction to Trainer\n",
    "\n",
    "在 Transformers 库中，`Trainer` 类是一个非常重要的组件，用于简化训练、评估、和使用 Transformer 模型的过程。\n",
    "\n",
    "`Trainer` 类的主要特点包括：\n",
    "\n",
    "1. **简化的训练流程**：`Trainer` 封装了许多复杂的训练步骤，如梯度累积、模型保存、日志记录等，使得训练过程更加简单直观。\n",
    "\n",
    "2. **灵活的数据处理**：它与 Hugging Face 的 `Datasets` 库紧密集成，支持高效的数据加载和预处理。\n",
    "\n",
    "3. **易于定制**：虽然 `Trainer` 提供了许多默认的设置，但它也允许用户通过参数和继承来定制训练过程。\n",
    "\n",
    "4. **多种训练配置**：它支持多种训练设置，包括单 GPU、多 GPU、TPU 训练等。\n",
    "\n",
    "5. **集成评估和预测**：除了训练，`Trainer` 还提供评估和预测的功能，使得从训练到部署的过程更加连贯。\n",
    "\n",
    "6. **自动化的最佳实践**：`Trainer` 采用了许多最佳实践，如动态学习率调整、权重衰减等，以优化训练效果。\n",
    "\n",
    "使用 `Trainer` 时，通常需要定义以下几个主要组件：\n",
    "\n",
    "- **模型**：一个来自于 Transformers 库的预训练模型。\n",
    "- **数据集**：用于训练和评估的数据集，通常是 `Dataset` 对象。\n",
    "- **训练参数**：一个 `TrainingArguments` 对象，用于配置训练过程中的各种参数（如学习率、训练轮次、批大小等）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在介绍 `Trainer` 之前，可以先回顾一下常见的 PyTorch 框架下是如何训练模型的：\n",
    "\n",
    "首先是定义网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class RN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RN, self).__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(26, 64),\n",
    "            nn.Hardsigmoid(),\n",
    "            nn.Linear(64, 26),\n",
    "            nn.Hardsigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.linear_stack_2 = nn.Sequential(\n",
    "            nn.Linear(26, 64),\n",
    "            nn.Hardsigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Hardsigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(64, 26)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.linear_stack(x)\n",
    "        # 残差\n",
    "        y = y+x\n",
    "        y = self.linear_stack_2(y)\n",
    "        y = self.output_layer(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "model = RN().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 loss_function 和 optimizer："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    " \n",
    "# 交叉熵和Adam\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    path = \"./model.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "     \n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "def train(num_epochs):\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs): \n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() \n",
    "            if i % 1000 == 999:    \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述过程可以看出，一般情况下借助 PyTorch 训练模型虽然谈不上麻烦，但是也总是有一个固定的结构框架，往往我们只需要在这个框架中填充我们需要的内容即可。而 `Trainer` 对这个框架进行了封装，提供了基于 PyTorch 框架的 api，从而简化了这一过程：\n",
    "\n",
    "首先导入必要的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ysy/.conda/envs/tf/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着准备训练数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0'),\n",
       " tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19, 20, 21, 22, 23, 24, 25,  0]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.zeros((26, 26), dtype=torch.float32).to(device=device)\n",
    "labels = []\n",
    "for i in range(26):\n",
    "    labels.append((i+1) % 26)\n",
    "    X[i][i] = 1.\n",
    "labels = torch.tensor(labels)\n",
    "dataset = Dataset.from_dict({'x':X, 'labels':labels})\n",
    "\n",
    "X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['x', 'labels'],\n",
       "    num_rows: 26\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后定义网络结构。这里要注意，由于 `Trainer` 在训练时，会将 `dataset` 中的数据按照对应的键值传入，因此需要在自己的 `forward` 方法中接受键值变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RN, self).__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(26, 64),\n",
    "            nn.Hardsigmoid(),\n",
    "            nn.Linear(64, 26),\n",
    "            nn.Hardsigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.linear_stack_2 = nn.Sequential(\n",
    "            nn.Linear(26, 64),\n",
    "            nn.Hardsigmoid(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Hardsigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(64, 26)\n",
    "        \n",
    "        self.loss_f = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x, labels, mode='train'):\n",
    "        y = self.linear_stack(x)\n",
    "        y = y+x\n",
    "        y = self.linear_stack_2(y)\n",
    "        y = self.output_layer(y)\n",
    "       \n",
    "        if mode is 'train':\n",
    "            return {\n",
    "                'loss':self.loss_f(y, labels),\n",
    "                'predictions':y\n",
    "            }\n",
    "        \n",
    "        return y\n",
    "    \n",
    "model = RN().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义评估函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = (labels == preds).sum()/len(labels)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         # 结果输出地址\n",
    "    num_train_epochs=1000,          # 训练总批次\n",
    "    per_device_train_batch_size=1,  # 训练批大小\n",
    "    per_device_eval_batch_size=1,   # 评估批大小\n",
    "    logging_dir='./logs/rn_log',    # 日志存储位置\n",
    "    learning_rate=1e-3,             # 学习率\n",
    "    save_steps=False,               # 不保存检查点\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      # 模型\n",
    "    args=training_args,               # 训练参数\n",
    "    train_dataset=dataset,            # 训练集\n",
    "    eval_dataset=dataset,             # 测试集\n",
    "    compute_metrics=compute_metrics   # 计算指标方法\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要自定义训练，可以继承 `Trainer` 并覆盖以下方法：\n",
    "\n",
    "- get_train_dataloader — 创建训练 DataLoader。\n",
    "- get_eval_dataloader — 创建评估 DataLoader。\n",
    "- get_test_dataloader — 创建测试 DataLoader。\n",
    "- log — 记录观察训练的各种对象的信息。\n",
    "- create_optimizer_and_scheduler — 设置优化器和学习率调度器, 还可以单独继承或覆盖 create_optimizer 和 create_scheduler 方法。\n",
    "- create_optimizer — 如果在初始化时没有传递，则设置优化器。\n",
    "- create_scheduler — 如果在初始化时没有传递，则设置学习率调度器。\n",
    "- compute_loss - 计算单批训练输入的损失。\n",
    "- training_step — 执行一步训练。\n",
    "- prediction_step — 执行一步评估/测试。\n",
    "- evaluate — 运行评估循环并返回指标。\n",
    "- predict — 返回在测试集上的预测（如果有标签，则包括指标）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
